{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weight Aggregation\n",
    "\n",
    "## Notation\n",
    "\n",
    "$S$: Server weights  \n",
    "$C_i$: Client i's weights  \n",
    "$K$: Number of clients  \n",
    "$K_P$: Number of participating clients in round  \n",
    "$n$: total amount of data accross clients  \n",
    "$n_i$: ammount of data for client i  \n",
    "$C_i^M$: Client i's mask. 1's for unpruned weight locations, 0's for pruned.  \n",
    "$1 - C_i^M$: Inverse of client i's mask with 1's for pruned weights.  \n",
    "$C_i^M \\odot W$: Client i's mask applied to W.  \n",
    "$C_i \\otimes S$: Unmasked client i's weights, otherwise S's weights.  \n",
    "Note: $C_i \\otimes S = C_i^M \\odot C_i + (1 - C_i^M) \\odot S$\n",
    "\n",
    "## Aggregation methods\n",
    "\n",
    "I'm actually not sure which aggregatio methods we have, exactly. It is good to write these down concisely. Here is a start.\n",
    "\n",
    "1. $\\frac{1}{K}\\sum_{i \\in all}\\frac{n_i}{n}{C_i}$\n",
    "1. $\\frac{1}{K}\\sum_{i \\in all}{C_i}$\n",
    "1. $\\frac{1}{K_P}\\sum_{i \\in part}{C_i}$\n",
    "1. $\\frac{1}{K_P}\\sum_{i \\in part}{C_i \\otimes S}$\n",
    "\n",
    "I don't believe I've captured Donglin's scenario were some weights are set to the randomly initialized weights \"Lotter FL V1 in this diagram\".\n",
    "\n",
    "Comments:\n",
    "1. This is the basic FedAvg\n",
    "1. This is a simple average without taking into account volume of client data. If clients have a lottery network, then their 0's will be included in the average.\n",
    "1. Like the previous, but restricted to participating clients. The result completely replaces the global weights.\n",
    "1. Each participating client only affects the weights the trainined on (i.e. that are not masked out). By setting the remainder of the weights to the global weights, this client won't be advesely influencing weights that it did not train. Each client does this independently before the average is taken.\n",
    "\n",
    "# Feedback On The Diagram\n",
    "\n",
    "This diagram highlights one of the main issues we discussed. In doesn't summarize the 3 approaches though. So, I have the following suggestions for your consideration.\n",
    "\n",
    "1. We can focus on how aggregation works for a single round (the simpler the better for the audience). So you can remove boxes 1 and 2, and box 3 is becomes Global Weights.\n",
    "1. We can reduce the # of sampled clients to 2, to make it quicker to review the aggregation approaches\n",
    "1. In the second row, I think it is fair to assume all unmasked weights are updated. You have 3 classes - masked weights, updated unmasked weights, and not updated unmasked weights. Let's just have masked weights and unmasked weights. This means having 0's instead of white boxes. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
