{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import functools, operator\n",
    "from abc import ABC, abstractmethod\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_root = './model_MNIST/server'\n",
    "clients_root = './model_MNIST/clients'\n",
    "\n",
    "def get_server_weights_fname():\n",
    "    return f'{server_root}/weights'\n",
    "\n",
    "def get_client_weights_fname(k):\n",
    "    return f'{clients_root}/{k}/weights'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERBOSE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(msg):\n",
    "    if VERBOSE > 0:\n",
    "        print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function expects data to be a list/tuple of length 2 with samples and labels: (X, y)\n",
    "# Both the samples and labels are split into k chunks\n",
    "#\n",
    "# The returned partition is a tuple of length k. Each tuple entry is a list (X, y)\n",
    "# of samples and labels.\n",
    "#\n",
    "# TODO: extend to support non-IID\n",
    "def split_data(data, k):\n",
    "    partition = []\n",
    "    data = (data[0][:5000], data[1][:5000])   #    !!!!!!!!!!!!! Chopped the data set size during development\n",
    "    n = len(data[0])\n",
    "    splits = [(n // k) * i for i in range(k)]\n",
    "\n",
    "    for i in range(len(splits)):\n",
    "        if i == len(splits) - 1:\n",
    "            partition.append((data[0][splits[i]:, :],\n",
    "                              data[1][splits[i]:]))\n",
    "        else:\n",
    "            partition.append((data[0][splits[i]:splits[i + 1], :],\n",
    "                              data[1][splits[i]:splits[i + 1]]))\n",
    "    return partition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weight-zeroing Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZeroMaskedWeightsCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, debug=False):\n",
    "        self.debug = debug\n",
    "\n",
    "\n",
    "    def _debug_zero_weights(self, client):\n",
    "        by_mask = np.count_nonzero(client.get_mask())\n",
    "        by_weights = np.count_nonzero(flatten_prunable(client.model.get_weights()))\n",
    "        print(f'active by mask: {by_mask}, non zero count: {by_weights}')\n",
    "\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        if self.debug:\n",
    "            print('-----')\n",
    "            self._debug_zero_weights(self.model.client)\n",
    "\n",
    "        weights = self.model.get_weights()\n",
    "        weights = unflatten_prunable(flatten_prunable(weights) * self.model.client.get_mask(), weights)\n",
    "        self.model.set_weights(weights)\n",
    "\n",
    "        if self.debug:\n",
    "            self._debug_zero_weights(self.model.client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flatten Prunable Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_prunable(weights):\n",
    "    return np.concatenate([layer.reshape(1,-1) for layer in weights if layer.ndim > 1], axis=1)\n",
    "\n",
    "\n",
    "def unflatten_prunable(flattened, orig_weights):\n",
    "    curr_offset = 0\n",
    "    result      = []\n",
    "\n",
    "    for layer in orig_weights:\n",
    "        if layer.ndim > 1:\n",
    "            count = np.prod(layer.shape)\n",
    "            result.append(flattened[0, curr_offset:curr_offset+count].reshape(layer.shape))\n",
    "            curr_offset += count\n",
    "        else:\n",
    "            result.append(layer)            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClientBase:\n",
    "    def __init__(self, k, model, hyper_params, X, y):\n",
    "        self.k              = k\n",
    "        self.model          = model\n",
    "        self.model.client   = self\n",
    "        self.hyper_params   = hyper_params\n",
    "        self.X              = X\n",
    "        self.y              = y\n",
    "\n",
    "\n",
    "    def get_weights(self):\n",
    "        return self.model.get_weights()\n",
    "\n",
    "\n",
    "    def sample_size(self):\n",
    "        return self.X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Client_FedAvg(ClientBase):\n",
    "    def __init__(self, k, model_creator, hyper_params, X, y):\n",
    "        super().__init__(k, model_creator(), hyper_params, X, y)\n",
    "        self.model_creator = model_creator\n",
    "\n",
    "\n",
    "    def client_update(self, weights):\n",
    "        self.model.set_weights(weights)\n",
    "        self.model.fit(self.X, self.y,\n",
    "                       batch_size=self.hyper_params['B'], epochs=self.hyper_params['E'],\n",
    "                       verbose=VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Client_LotteryFL(ClientBase):\n",
    "    def __init__(self, k, model_creator, initial_weights, hyper_params, X, y):\n",
    "        super().__init__(k, model_creator(), hyper_params, X, y)\n",
    "        self.initial_weights = initial_weights\n",
    "        self.mask            = np.ones(flatten_prunable(initial_weights).shape, dtype=int)\n",
    "        self.curr_prune_rate = 0\n",
    "\n",
    "\n",
    "    def prune(weights, mask, r_p):\n",
    "        alive            = weights[np.nonzero(weights*mask)] # flattened array of nonzero values\n",
    "        percentile_value = np.percentile(abs(alive), r_p*100)\n",
    "        return np.where(abs(weights) < percentile_value, 0, mask)\n",
    "    \n",
    "    \n",
    "    def get_mask(self):\n",
    "        return self.mask\n",
    "\n",
    "    \n",
    "    # This returns a longer mask that includes 1's for all non-prunable parameters (e.g. bias)\n",
    "    def get_mask_extended(self):\n",
    "        curr_offset = 0\n",
    "        result      = []\n",
    "\n",
    "        for layer in self.model.get_weights():\n",
    "            if layer.ndim > 1:\n",
    "                count = np.prod(layer.shape)\n",
    "                result.extend(self.mask[0, curr_offset:curr_offset+count])\n",
    "                curr_offset += count\n",
    "            else:\n",
    "                result.extend(np.ones(layer.size, dtype=int))\n",
    "        return np.array(result)\n",
    "\n",
    "\n",
    "    def get_weights(self):\n",
    "        weights = self.model.get_weights()\n",
    "        return unflatten_prunable(flatten_prunable(weights) * self.mask, weights)\n",
    "    \n",
    "\n",
    "    def client_update(self, weights):\n",
    "        self.model.set_weights(weights)\n",
    "        acc = self.model.evaluate(self.X, self.y, return_dict=True, verbose=VERBOSE)['accuracy']\n",
    "        \n",
    "        print(f'Client: accuracy {acc}, prune rate {self.curr_prune_rate}')\n",
    "        if acc > self.hyper_params['acc_threshold'] and self.curr_prune_rate < self.hyper_params['r_target']:\n",
    "            print('Client is pruning.')\n",
    "            self.mask = Client_LotteryFL.prune(flatten_prunable(weights), self.mask, self.hyper_params['r_p'])\n",
    "            self.curr_prune_rate = (self.mask.size - np.count_nonzero(self.mask)) / self.mask.size\n",
    "            \n",
    "            new_weights = unflatten_prunable(flatten_prunable(self.initial_weights) * self.mask, self.initial_weights)\n",
    "            self.model.set_weights(new_weights)\n",
    "        \n",
    "        self.model.fit(self.X, self.y,\n",
    "                       batch_size=self.hyper_params['B'], epochs=self.hyper_params['E'],\n",
    "                       callbacks=[ZeroMaskedWeightsCallback()],\n",
    "                       verbose=VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_MNIST_model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\n",
    "        tf.keras.layers.Dense(128,activation='relu'),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')])\n",
    "    \n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "                     optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "                     metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Foreman: run with initial weights\n",
      "1875/1875 [==============================] - 1s 654us/step - loss: 178.2424 - accuracy: 0.0720\n",
      "Selected clients:  [1 5 8 4 9]\n",
      "Selected clients:  [4 9 2 5 3]\n",
      "Foreman: run with trained global model\n",
      "1875/1875 [==============================] - 1s 660us/step - loss: 0.9717 - accuracy: 0.8373\n",
      "Foreman: rerun with initial weights\n",
      "1875/1875 [==============================] - 1s 652us/step - loss: 178.2424 - accuracy: 0.0720\n"
     ]
    }
   ],
   "source": [
    "fm = Foreman({\n",
    "    'algo': 'FedAvg',\n",
    "    'data': 'MNIST_IID',\n",
    "    'R': 2,\n",
    "    'C': .5,\n",
    "    'K': 10,\n",
    "    'E': 4,\n",
    "    'B': 64,\n",
    "    'eta': 0.01 # currently unused\n",
    "    })\n",
    "fm.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ServerBase(ABC):\n",
    "    def __init__(self, clients, model, hyper_params, X, y):\n",
    "        self.clients      = clients\n",
    "        self.model        = model # the global model\n",
    "        self.weights      = model.get_weights()\n",
    "        self.hyper_params = hyper_params\n",
    "        self.X            = X\n",
    "        self.y            = y\n",
    "        self.n            = functools.reduce(operator.add, [c.sample_size() for c in self.clients]) # total samples\n",
    "        self.shapes       = [layer.shape for layer in self.weights]\n",
    "    \n",
    "    def _sampleClients(self):\n",
    "        choices = np.random.choice(self.hyper_params['K'],\n",
    "                                   max(1, int(self.hyper_params['C']*self.hyper_params['K'])),\n",
    "                                   replace=False)\n",
    "        return [self.clients[i] for i in choices]\n",
    "\n",
    "\n",
    "    def _flatten(weights):\n",
    "        return np.concatenate([layer.reshape(1,-1) for layer in weights], axis=1)\n",
    "\n",
    "\n",
    "    def _unflatten(weights, shapes):\n",
    "        curr_offset = 0\n",
    "        result      = []\n",
    "\n",
    "        for s in shapes:\n",
    "            count = np.prod(s)\n",
    "            result.append(weights[0, curr_offset:curr_offset+count].reshape(s))\n",
    "            curr_offset += count\n",
    "        return result\n",
    "\n",
    "\n",
    "# PROPOSAL: replace this client-sample-based FedAvg with a FedAvg over all clients\n",
    "#           which is what I think the FedAvg algorithm actually wants.\n",
    "# OLD:\n",
    "#     def _fed_avg_aggregate(self, clients):\n",
    "#         return ServerBase._unflatten(\n",
    "#             (1/self.n) * functools.reduce(operator.add,\n",
    "#                                           [c.sample_size() * ServerBase._flatten(c.get_weights()) for c in clients]),\n",
    "#             self.shapes)\n",
    "# NEW:\n",
    "# Here we ignore the parameter clients and use self.clients, which is actually what FedAvg is supposed to do.\n",
    "# TODO: If accepted, get rid of argument and clean up calls.\n",
    "    def _fed_avg_aggregate(self, clients):\n",
    "        return ServerBase._unflatten(\n",
    "            (1/self.n) * functools.reduce(operator.add,\n",
    "                                          [c.sample_size() * ServerBase._flatten(c.get_weights()) for c in self.clients]),\n",
    "            self.shapes)\n",
    "\n",
    "\n",
    "    def get_weights(self):\n",
    "        return self.weights\n",
    "\n",
    "\n",
    "    @abstractmethod\n",
    "    def run(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Server_FedAvg(ServerBase):\n",
    "    def __init__(self, clients, model, hyper_params, X, y):\n",
    "        super().__init__(clients, model, hyper_params, X, y)\n",
    "    \n",
    "    def run(self):\n",
    "        for r in range(self.hyper_params['R']):\n",
    "            log(f'Server: round {r}')\n",
    "            clients = self._sampleClients()\n",
    "            for c in clients:\n",
    "                log(f'Server: round {r} - client{c.k}')\n",
    "                c.client_update(self.weights)\n",
    "            \n",
    "            self.weights = self._fed_avg_aggregate(clients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Server_LotteryFL(ServerBase):\n",
    "    def __init__(self, clients, model, hyper_params, X, y):\n",
    "        super().__init__(clients, model, hyper_params, X, y)\n",
    "    \n",
    "    def run(self):\n",
    "        for r in range(self.hyper_params['R']):\n",
    "            log(f'Server: round {r}')\n",
    "            clients = self._sampleClients()\n",
    "            for c in clients:\n",
    "                log(f'Server: round {r} - client{c.k}')\n",
    "                weights = unflatten_prunable(flatten_prunable(self.weights) * c.get_mask(), self.weights)\n",
    "                c.client_update(weights)\n",
    "            \n",
    "            self.weights = self._fed_avg_aggregate(clients) # revisit this approach to aggregation for LotteryFL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROPOSAL: replace this simple FedAvg which one more appropriate for LotteryFL\n",
    "# OLD:\n",
    "# self.weights = self._fed_avg_aggregate(clients) # revisit this approach to aggregation for LotteryFL\n",
    "# NEW:\n",
    "#TODO: If accepted, clean up the code.\n",
    "class Server_LotteryFL(ServerBase):\n",
    "    def __init__(self, clients, model, hyper_params, X, y):\n",
    "        super().__init__(clients, model, hyper_params, X, y)\n",
    "    \n",
    "    def run(self):\n",
    "        for r in range(self.hyper_params['R']):\n",
    "            log(f'Server: round {r}')\n",
    "            clients = self._sampleClients()\n",
    "            for c in clients:\n",
    "                log(f'Server: round {r} - client{c.k}')\n",
    "                weights = unflatten_prunable(flatten_prunable(self.weights) * c.get_mask(), self.weights)\n",
    "                c.client_update(weights)\n",
    "            \n",
    "            sizes_weights = []\n",
    "            flat_g_weights = ServerBase._flatten(self.get_weights())            \n",
    "            for c in self.clients:\n",
    "                flat_c_weights = ServerBase._flatten(c.get_weights())\n",
    "                mask           = c.get_mask_extended()\n",
    "                sizes_weights.append((c.sample_size(), mask*flat_c_weights + (1 - mask)*flat_g_weights))\n",
    "                \n",
    "            self.weights = ServerBase._unflatten((1/self.n) * functools.reduce(operator.add,\n",
    "                                                                               [c[0] * c[1] for c in sizes_weights]),\n",
    "                                                 self.shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Server_Genesis(ServerBase):\n",
    "    def __init__(self, clients, model, hyper_params, X, y):\n",
    "        super().__init__(clients, model, hyper_params, X, y)\n",
    "    \n",
    "    def run(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foreman\n",
    "\n",
    "* deals with parameters for the experiment to be run\n",
    "* loads the requested data\n",
    "* pick the right model for the data\n",
    "* creates the global model\n",
    "* creates the clients\n",
    "* creates the server\n",
    "\n",
    "## Foreman parameters\n",
    "The parameters are all grouped together, but different parameters are intended for different audiences.\n",
    "\n",
    "### experiment parameters\n",
    "Parameters which govern the experiment to be run.\n",
    "* <b>algo</b>:\n",
    "    * \"FedAvg\" for algorithm from McMahan et al.\n",
    "    * \"LotteryFL\" for algorithm from Li et al.\n",
    "    * \"Genesis\" for our modification.\n",
    "* <b>data</b>: The dataset to use. For now, this determins the NN model that will be used.\n",
    "    * \"MNIST_IID\"\n",
    "    * \"MNIST_NON-IID\"\n",
    "    * \"CIFAR10_IID\"\n",
    "    * \"CIFAR10_NON-IID\"\n",
    "* <b>K</b>: number of clients\n",
    "\n",
    "### client parameters\n",
    "Hyper parameters required for clients and server as specified in the articles by McMahan et al. and Li et al.\n",
    "\n",
    "* <b>E</b>: number of epochs clients will train in a single round\n",
    "* <b>B</b>: client minibatch size\n",
    "* <b>eta</b>: the learning rate\n",
    "* <b>acc_threshold</b>: the accuracy threshold required before pruning\n",
    "* <b>r_target</b>: the target pruning rate, between 0 and 1\n",
    "* <b>r_p</b>: the pruning rate to use on a given iteration, between 0 and 1\n",
    "\n",
    "### For Server\n",
    "Hyper parameters for the server.\n",
    "\n",
    "* <b>R</b>: number of rounds\n",
    "* <b>C</b>: the fraction of clients to run a round on (C=0 means 1 client)\n",
    "* <b>K</b>: number of clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Foreman():\n",
    "    def __init__(self, params):\n",
    "        self.params = params\n",
    "        \n",
    "        # load data, initialize model_creator\n",
    "        if params['data'] == 'MNIST_IID':\n",
    "            (self.X_train, self.y_train), (self.X_test, self.y_test) = tf.keras.datasets.mnist.load_data()\n",
    "            self.model_creator = create_MNIST_model\n",
    "        else:\n",
    "            assert False, f\"Unsupported argument for data: {params['data']}\"\n",
    "        \n",
    "        # split data\n",
    "        partition = split_data((self.X_train, self.y_train), params['K'])\n",
    "        \n",
    "        # create global model\n",
    "        self.global_model          = self.model_creator()\n",
    "        self.initial_weights       = self.global_model.get_weights()\n",
    "\n",
    "        # handle clients\n",
    "        self.clients = []\n",
    "        for k in range(self.params['K']):\n",
    "            if params['algo'] == 'FedAvg':\n",
    "                self.clients.append(Client_FedAvg(k,\n",
    "                                                  self.model_creator,\n",
    "                                                  {key: params[key] for key in ('E', 'B', 'eta')},\n",
    "                                                  partition[k][0],\n",
    "                                                  partition[k][1]))\n",
    "            elif params['algo'] == 'LotteryFL':\n",
    "                self.clients.append(Client_LotteryFL(k,\n",
    "                                                     self.model_creator,\n",
    "                                                     self.initial_weights,\n",
    "                                                     {key: params[key] for key in ('E', 'B', 'eta', 'acc_threshold',\n",
    "                                                                                   'r_target', 'r_p')},\n",
    "                                                     partition[k][0],\n",
    "                                                     partition[k][1]))\n",
    "            else:\n",
    "                assert False, f\"Unsupported argument for algo: {params['algo']}\"\n",
    "\n",
    "        # handle server\n",
    "        if params['algo'] == 'FedAvg':\n",
    "            self.server = Server_FedAvg(self.clients, self.global_model,\n",
    "                                        {key: params[key] for key in ('R', 'C', 'K')},\n",
    "                                        self.X_train, self.y_train)\n",
    "        elif params['algo'] == 'LotteryFL':\n",
    "            self.server = Server_LotteryFL(self.clients, self.global_model,\n",
    "                                          {key: params[key] for key in ('R', 'C', 'K')},\n",
    "                                           self.X_train, self.y_train)\n",
    "        else:\n",
    "            self.server = Server_Genesis(self.clients, self.global_model,\n",
    "                                         {key: params[key] for key in ('R', 'C', 'K')},\n",
    "                                         self.X_train, self.y_train)\n",
    "        \n",
    "\n",
    "\n",
    "    def run(self):\n",
    "        print(\"Foreman: run with initial weights\")\n",
    "        self.global_model.evaluate(self.X_train, self.y_train)\n",
    "        \n",
    "        self.server.run()\n",
    "        print(\"Foreman: run with trained global model\")\n",
    "        self.global_model.set_weights(self.server.get_weights())\n",
    "        self.global_model.evaluate(self.X_train, self.y_train)\n",
    "        \n",
    "        # we evaluate final client and server model performance at this point\n",
    "        print(\"Foreman: rerun with initial weights\")\n",
    "        self.global_model.set_weights(self.initial_weights)\n",
    "        self.global_model.evaluate(self.X_train, self.y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_experiment(dict):\n",
    "    exp = {}\n",
    "    for k, v in dict.items():\n",
    "        expand = False\n",
    "        if isinstance(v, list):\n",
    "            if isinstance(v[0], int):\n",
    "                exp[k] = list(np.linspace(v[0], v[1], v[2]).astype(int))\n",
    "            elif isinstance(v[0], float):\n",
    "                exp[k] = list(np.around(np.linspace(v[0], v[1], v[2]), 4))\n",
    "            else:\n",
    "                assert False, \"Experiments can only iterate over ints and floats.\"\n",
    "        else:\n",
    "            exp[k] = [v]\n",
    "\n",
    "    runs = []\n",
    "    for algo in exp['algo']:\n",
    "        for data in exp['data']:\n",
    "            for R in exp['R']:\n",
    "                for C in exp['C']:\n",
    "                    for K in exp['K']:\n",
    "                        for E in exp['E']:\n",
    "                            for B in exp['B']:\n",
    "                                for eta in exp['eta']:\n",
    "                                    runs.append({'algo': algo,\n",
    "                                                 'data': data,\n",
    "                                                  'R': R,\n",
    "                                                  'C': C,\n",
    "                                                  'K': K,\n",
    "                                                  'E': E,\n",
    "                                                  'B': B,\n",
    "                                                  'eta': eta})\n",
    "    return runs\n",
    "\n",
    "\n",
    "def run(dict):\n",
    "    experiments = expand_experiment(dict)\n",
    "    for exp in experiments:\n",
    "        print(exp)\n",
    "        fm = Foreman(exp)\n",
    "        fm.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm = Foreman({\n",
    "    'algo': 'FedAvg',\n",
    "    'data': 'MNIST_IID',\n",
    "    'R': 10,\n",
    "    'C': 1,\n",
    "    'K': 3,\n",
    "    'E': 4,\n",
    "    'B': 64,\n",
    "    'eta': 0.01 # currently unused\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Foreman: run with initial weights\n",
      "32/32 [==============================] - 0s 750us/step - loss: 129.4162 - accuracy: 0.1050\n",
      "Foreman: run with trained global model\n",
      "32/32 [==============================] - 0s 781us/step - loss: 0.0360 - accuracy: 0.9920\n",
      "Foreman: rerun with initial weights\n",
      "32/32 [==============================] - 0s 687us/step - loss: 129.4162 - accuracy: 0.1050\n"
     ]
    }
   ],
   "source": [
    "fm.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm = Foreman({\n",
    "    'algo': 'LotteryFL',\n",
    "    'data': 'MNIST_IID',\n",
    "    'R': 10,\n",
    "    'C': 1,\n",
    "    'K': 3,\n",
    "    'E': 4,\n",
    "    'B': 64,\n",
    "    'eta': 0.01, # currently unused\n",
    "    'acc_threshold': .5,\n",
    "    'r_target': .25,\n",
    "    'r_p': .25\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Foreman: run with initial weights\n",
      "32/32 [==============================] - 0s 781us/step - loss: 162.7151 - accuracy: 0.0980\n",
      "Client: accuracy 0.09799999743700027, prune rate 0\n",
      "Client: accuracy 0.08799999952316284, prune rate 0\n",
      "Client: accuracy 0.06800000369548798, prune rate 0\n",
      "Client: accuracy 0.8859999775886536, prune rate 0\n",
      "Client is pruning.\n",
      "Client: accuracy 0.8659999966621399, prune rate 0\n",
      "Client is pruning.\n",
      "Client: accuracy 0.8939999938011169, prune rate 0\n",
      "Client is pruning.\n",
      "Client: accuracy 0.8880000114440918, prune rate 0.25\n",
      "Client: accuracy 0.875, prune rate 0.25\n",
      "Client: accuracy 0.8930000066757202, prune rate 0.25\n",
      "Client: accuracy 0.9240000247955322, prune rate 0.25\n",
      "Client: accuracy 0.9269999861717224, prune rate 0.25\n",
      "Client: accuracy 0.9359999895095825, prune rate 0.25\n",
      "Client: accuracy 0.9539999961853027, prune rate 0.25\n",
      "Client: accuracy 0.9459999799728394, prune rate 0.25\n",
      "Client: accuracy 0.9610000252723694, prune rate 0.25\n",
      "Client: accuracy 0.9670000076293945, prune rate 0.25\n",
      "Client: accuracy 0.9620000123977661, prune rate 0.25\n",
      "Client: accuracy 0.9710000157356262, prune rate 0.25\n",
      "Client: accuracy 0.9779999852180481, prune rate 0.25\n",
      "Client: accuracy 0.968999981880188, prune rate 0.25\n",
      "Client: accuracy 0.984000027179718, prune rate 0.25\n",
      "Client: accuracy 0.9890000224113464, prune rate 0.25\n",
      "Client: accuracy 0.9850000143051147, prune rate 0.25\n",
      "Client: accuracy 0.9869999885559082, prune rate 0.25\n",
      "Client: accuracy 0.9890000224113464, prune rate 0.25\n",
      "Client: accuracy 0.9919999837875366, prune rate 0.25\n",
      "Client: accuracy 0.9950000047683716, prune rate 0.25\n",
      "Client: accuracy 0.9959999918937683, prune rate 0.25\n",
      "Client: accuracy 0.996999979019165, prune rate 0.25\n",
      "Client: accuracy 0.996999979019165, prune rate 0.25\n",
      "Foreman: run with trained global model\n",
      "32/32 [==============================] - 0s 750us/step - loss: 0.1375 - accuracy: 0.9850\n",
      "Foreman: rerun with initial weights\n",
      "32/32 [==============================] - 0s 719us/step - loss: 162.7151 - accuracy: 0.0980\n"
     ]
    }
   ],
   "source": [
    "fm.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm = Foreman({\n",
    "    'algo': 'LotteryFL',\n",
    "    'data': 'MNIST_IID',\n",
    "    'R': 10,\n",
    "    'C': 1,\n",
    "    'K': 3,\n",
    "    'E': 4,\n",
    "    'B': 64,\n",
    "    'eta': 0.01, # currently unused\n",
    "    'acc_threshold': .5,\n",
    "    'r_target': .25,\n",
    "    'r_p': .25\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dev Zone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get_weights\n",
    "\n",
    "* returns a copy of the models weights (not a view)\n",
    "  * getting the weights, and then modifying them does not change the models weights\n",
    "* np.reshape() returns a view\n",
    "  * modifying the reshaped array changes values in the original array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_MNIST_model():\n",
    "    small = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(4, 1)),\n",
    "    tf.keras.layers.Dense(3,activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')])\n",
    "    \n",
    "    small.compile(loss='sparse_categorical_crossentropy',\n",
    "                     optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "                     metrics=['accuracy'])\n",
    "    return small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "small = create_MNIST_model()\n",
    "w1 = small.get_weights()\n",
    "small = create_MNIST_model()\n",
    "w2 = small.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_119\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_119 (Flatten)        (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_246 (Dense)            (None, 3)                 15        \n",
      "_________________________________________________________________\n",
      "dense_247 (Dense)            (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 19\n",
      "Trainable params: 19\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "small.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 0.17254543, -0.0792715 , -0.06162965],\n",
      "       [-0.8082738 ,  0.6968483 ,  0.7035241 ],\n",
      "       [-0.47015384, -0.27038056, -0.0319612 ],\n",
      "       [ 0.54134417, -0.7661829 ,  0.6768354 ]], dtype=float32), array([0., 0., 0.], dtype=float32), array([[-0.58530414],\n",
      "       [-0.01651156],\n",
      "       [ 0.20637381]], dtype=float32), array([0.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(small.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flatten_9\n",
      "[]\n",
      "dense_18\n",
      "[array([[ 0.2721634 , -0.7472533 , -0.749786  ],\n",
      "       [ 0.22996092,  0.10714316,  0.77423966],\n",
      "       [-0.05542952, -0.68133324, -0.0448913 ],\n",
      "       [ 0.8466245 , -0.18048984, -0.5477376 ]], dtype=float32), array([0., 0., 0.], dtype=float32)]\n",
      "dense_19\n",
      "[array([[-0.94444585],\n",
      "       [ 0.58059597],\n",
      "       [ 0.80115783]], dtype=float32), array([0.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "for l in small.layers:\n",
    "    print(l.name)\n",
    "    print(l.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 0.0665496 ,  0.29469514,  0.6695316 ],\n",
      "       [ 0.5417086 ,  0.22732794, -0.62357455],\n",
      "       [ 0.0511561 ,  0.702634  , -0.6886611 ],\n",
      "       [ 0.88815427,  0.5211091 ,  0.30948365]], dtype=float32), array([0., 0., 0.], dtype=float32), array([[ 0.31030083],\n",
      "       [-0.5062242 ],\n",
      "       [-0.47649813]], dtype=float32), array([0.], dtype=float32)] \n",
      "\n",
      " [array([[ 0.8556472 ,  0.42359066, -0.7557968 ],\n",
      "       [-0.6710422 ,  0.2830696 , -0.05207503],\n",
      "       [-0.5654651 ,  0.88744247, -0.14415038],\n",
      "       [ 0.609658  , -0.6553073 ,  0.11074495]], dtype=float32), array([0., 0., 0.], dtype=float32), array([[0.45865822],\n",
      "       [0.20319712],\n",
      "       [0.46475327]], dtype=float32), array([0.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(w1, \"\\n\\n\", w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(weights):\n",
    "    return np.concatenate([layer.reshape(1,-1) for layer in weights], axis=1)\n",
    "\n",
    "def unflatten(weights, shapes):\n",
    "    curr_offset = 0\n",
    "    result      = []\n",
    "    \n",
    "    for s in shapes:\n",
    "        count = np.prod(s)\n",
    "        result.append(weights[0, curr_offset:curr_offset+count].reshape(s))\n",
    "        curr_offset += count\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = flatten(w1)\n",
    "f2 = flatten(w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0665496   0.29469514  0.6695316   0.5417086   0.22732794 -0.62357455\n",
      "   0.0511561   0.702634   -0.6886611   0.88815427  0.5211091   0.30948365\n",
      "   0.          0.          0.          0.31030083 -0.5062242  -0.47649813\n",
      "   0.        ]]\n",
      "[[ 0.8556472   0.42359066 -0.7557968  -0.6710422   0.2830696  -0.05207503\n",
      "  -0.5654651   0.88744247 -0.14415038  0.609658   -0.6553073   0.11074495\n",
      "   0.          0.          0.          0.45865822  0.20319712  0.46475327\n",
      "   0.        ]]\n",
      "[[ 0.9221968   0.7182858  -0.08626521 -0.12933362  0.51039755 -0.6756496\n",
      "  -0.514309    1.5900764  -0.8328115   1.4978123  -0.13419819  0.4202286\n",
      "   0.          0.          0.          0.76895905 -0.3030271  -0.01174486\n",
      "   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(f1)\n",
    "print(f2)\n",
    "print((f1 + f2))\n",
    "s1 = (f1 + f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "uf1 = unflatten(f1, [layer.shape for layer in w1])\n",
    "uf2 = unflatten(f1, [layer.shape for layer in w2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 0.8949822 ,  0.8161237 ,  0.91389   ],\n",
      "       [ 0.27480912,  0.0522331 , -0.7874019 ],\n",
      "       [-0.82874143, -0.07225156, -0.24778724],\n",
      "       [ 0.2698859 , -0.8677456 , -0.7338054 ]], dtype=float32), array([0., 0., 0.], dtype=float32), array([[ 0.6754428],\n",
      "       [ 1.0323585],\n",
      "       [-0.431778 ]], dtype=float32), array([0.], dtype=float32)]\n",
      "[array([[ 0.8949822 ,  0.8161237 ,  0.91389   ],\n",
      "       [ 0.27480912,  0.0522331 , -0.7874019 ],\n",
      "       [-0.82874143, -0.07225156, -0.24778724],\n",
      "       [ 0.2698859 , -0.8677456 , -0.7338054 ]], dtype=float32), array([0., 0., 0.], dtype=float32), array([[ 0.6754428],\n",
      "       [ 1.0323585],\n",
      "       [-0.431778 ]], dtype=float32), array([0.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(uf1)\n",
    "print(uf2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruning Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't prune biases\n",
    "# flatten before, unflatten afterwards\n",
    "# r_p should be between 0 and 1\n",
    "# returns new mask\n",
    "def prune(weights, mask, r_p):\n",
    "    print(weights)\n",
    "    alive = weights[np.nonzero(weights*mask)] # flattened array of nonzero values\n",
    "    print('alive before: ', alive.shape[0])\n",
    "    \n",
    "    percentile_value = np.percentile(abs(alive), r_p*100)\n",
    "    print(\"Cutoff: \", percentile_value)\n",
    "\n",
    "    new_mask = np.where(abs(weights) < percentile_value, 0, mask)\n",
    "    print('Alive after', np.count_nonzero(new_mask))\n",
    "    print('% pruned:', (alive.shape[0] - np.count_nonzero(new_mask))/alive.shape[0])\n",
    "    print(\"New mask 1:\\n\", new_mask)\n",
    "    print(\"Masked weights:\\n\", weights * new_mask)\n",
    "    return new_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prune 25%:\n",
      "[[ 0.89  0.82  0.91]\n",
      " [ 0.27  0.05 -0.79]\n",
      " [-0.83 -0.07 -0.25]\n",
      " [ 0.27 -0.87 -0.73]]\n",
      "alive before:  12\n",
      "Cutoff:  0.26500000804662704\n",
      "Alive after 9\n",
      "% pruned: 0.25\n",
      "New mask 1:\n",
      " [[1. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 1. 1.]]\n",
      "Masked weights:\n",
      " [[ 0.88999999  0.81999999  0.91000003]\n",
      " [ 0.27000001  0.         -0.79000002]\n",
      " [-0.82999998 -0.         -0.        ]\n",
      " [ 0.27000001 -0.87       -0.73000002]]\n",
      "Prune 33%:\n",
      "[[ 0.89  0.82  0.91]\n",
      " [ 0.27  0.05 -0.79]\n",
      " [-0.83 -0.07 -0.25]\n",
      " [ 0.27 -0.87 -0.73]]\n",
      "alive before:  9\n",
      "Cutoff:  0.7684000205993653\n",
      "Alive after 6\n",
      "% pruned: 0.3333333333333333\n",
      "New mask 1:\n",
      " [[1. 1. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]]\n",
      "Masked weights:\n",
      " [[ 0.88999999  0.81999999  0.91000003]\n",
      " [ 0.          0.         -0.79000002]\n",
      " [-0.82999998 -0.         -0.        ]\n",
      " [ 0.         -0.87       -0.        ]]\n"
     ]
    }
   ],
   "source": [
    "w1p = np.around(w1[0], 2)\n",
    "m1 = np.ones(w1p.shape)\n",
    "print('Prune 25%:')\n",
    "m2 = prune(w1p, m1, 0.25)\n",
    "print('Prune 33%:')\n",
    "m3 = prune(w1p, m2, 0.33)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pruning only weights, not biases\n",
    "\n",
    "When running FedAvg we need to flatten all parameters and take the average. But, when pruning, we need to flatten just the weights, not the biases. This makes for a complicated flatten/unflatten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A heuristic is used where by if the dimension of a tensor is 1, then we assume it is a bias tensor.\n",
    "# If this assumption does not hold for a certain layer type, we will likely have to pass a model in\n",
    "# rather than orig_weights.\n",
    "def _flatten_prunable(weights):\n",
    "    return np.concatenate([layer.reshape(1,-1) for layer in weights if layer.ndim > 1], axis=1)\n",
    "\n",
    "\n",
    "def _unflatten_prunable(flattened, orig_weights):\n",
    "    curr_offset = 0\n",
    "    result      = []\n",
    "\n",
    "    for layer in orig_weights:\n",
    "        if layer.ndim > 1:\n",
    "            count = np.prod(layer.shape)\n",
    "            result.append(flattened[0, curr_offset:curr_offset+count].reshape(layer.shape))\n",
    "            curr_offset += count\n",
    "        else:\n",
    "            result.append(layer)\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "w1p = _unflatten_prunable(_flatten_prunable(w1), w1)\n",
    "\n",
    "for l in range(len(w1)):\n",
    "    print(np.array_equal(w1[l], w1p[l]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 0.8949822 ,  0.8161237 ,  0.91389   ],\n",
      "       [ 0.27480912,  0.0522331 , -0.7874019 ],\n",
      "       [-0.82874143, -0.07225156, -0.24778724],\n",
      "       [ 0.2698859 , -0.8677456 , -0.7338054 ]], dtype=float32), array([0., 0., 0.], dtype=float32), array([[ 0.6754428],\n",
      "       [ 1.0323585],\n",
      "       [-0.431778 ]], dtype=float32), array([0.], dtype=float32)]\n",
      "[[ 0.8949822   0.8161237   0.91389     0.27480912  0.0522331  -0.7874019\n",
      "  -0.82874143 -0.07225156 -0.24778724  0.2698859  -0.8677456  -0.7338054\n",
      "   0.6754428   1.0323585  -0.431778  ]]\n",
      "[[ 0.          0.81612372  0.91389     0.27480912  0.0522331  -0.78740191\n",
      "  -0.82874143 -0.07225156 -0.24778724  0.2698859  -0.86774558 -0.73380542\n",
      "   0.67544281  1.03235853 -0.        ]]\n",
      "[array([[ 0.        ,  0.81612372,  0.91389   ],\n",
      "       [ 0.27480912,  0.0522331 , -0.78740191],\n",
      "       [-0.82874143, -0.07225156, -0.24778724],\n",
      "       [ 0.2698859 , -0.86774558, -0.73380542]]), array([0., 0., 0.], dtype=float32), array([[ 0.67544281],\n",
      "       [ 1.03235853],\n",
      "       [-0.        ]]), array([0.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(w1)\n",
    "f1 = _flatten_prunable(w1)\n",
    "print(f1)\n",
    "m = np.ones(f1.shape)\n",
    "m[0,0] = 0\n",
    "m[0,14] = 0\n",
    "print(f1 * m)\n",
    "w1fu = _unflatten_prunable(f1 * m, w1)\n",
    "print(w1fu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.        ,  0.81612372,  0.91389   ],\n",
       "        [ 0.27480912,  0.0522331 , -0.78740191],\n",
       "        [-0.82874143, -0.07225156, -0.24778724],\n",
       "        [ 0.2698859 , -0.86774558, -0.73380542]]),\n",
       " array([0., 0., 0.], dtype=float32),\n",
       " array([[ 0.67544281],\n",
       "        [ 1.03235853],\n",
       "        [-0.        ]]),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_unflatten_prunable(_flatten_prunable(w1) * m, w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't prune biases\n",
    "# flatten before, unflatten afterwards\n",
    "# r_p should be between 0 and 1\n",
    "# returns new mask\n",
    "def prune(weights, mask, r_p):\n",
    "    print(weights)\n",
    "    alive = weights[np.nonzero(weights*mask)] # flattened array of nonzero values\n",
    "    print('alive before: ', alive.shape[0])\n",
    "    \n",
    "    percentile_value = np.percentile(abs(alive), r_p*100)\n",
    "    print(\"Cutoff: \", percentile_value)\n",
    "\n",
    "    new_mask = np.where(abs(weights) < percentile_value, 0, mask)\n",
    "    print('Alive after', np.count_nonzero(new_mask))\n",
    "    print('% pruned:', (alive.shape[0] - np.count_nonzero(new_mask))/alive.shape[0])\n",
    "    print(\"New mask 1:\\n\", new_mask)\n",
    "    print(\"Masked weights:\\n\", weights * new_mask)\n",
    "    return new_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prune 33%:\n",
      "[[ 0.8949822   0.8161237   0.91389     0.27480912  0.0522331  -0.7874019\n",
      "  -0.82874143 -0.07225156 -0.24778724  0.2698859  -0.8677456  -0.7338054\n",
      "   0.6754428   1.0323585  -0.431778  ]]\n",
      "alive before:  15\n",
      "Cutoff:  0.3721298348903656\n",
      "Alive after 10\n",
      "% pruned: 0.3333333333333333\n",
      "New mask 1:\n",
      " [[1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1.]]\n",
      "Masked weights:\n",
      " [[ 0.89498222  0.81612372  0.91389     0.          0.         -0.78740191\n",
      "  -0.82874143 -0.         -0.          0.         -0.86774558 -0.73380542\n",
      "   0.67544281  1.03235853 -0.43177801]]\n",
      "Prune 20%:\n",
      "[[ 0.8949822   0.8161237   0.91389     0.27480912  0.0522331  -0.7874019\n",
      "  -0.82874143 -0.07225156 -0.24778724  0.2698859  -0.8677456  -0.7338054\n",
      "   0.6754428   1.0323585  -0.431778  ]]\n",
      "alive before:  10\n",
      "Cutoff:  0.7221328973770141\n",
      "Alive after 8\n",
      "% pruned: 0.2\n",
      "New mask 1:\n",
      " [[1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 0.]]\n",
      "Masked weights:\n",
      " [[ 0.89498222  0.81612372  0.91389     0.          0.         -0.78740191\n",
      "  -0.82874143 -0.         -0.          0.         -0.86774558 -0.73380542\n",
      "   0.          1.03235853 -0.        ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.89498222,  0.81612372,  0.91389   ],\n",
       "        [ 0.        ,  0.        , -0.78740191],\n",
       "        [-0.82874143, -0.        , -0.        ],\n",
       "        [ 0.        , -0.86774558, -0.73380542]]),\n",
       " array([0., 0., 0.], dtype=float32),\n",
       " array([[ 0.        ],\n",
       "        [ 1.03235853],\n",
       "        [-0.        ]]),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1 = _flatten_prunable(w1)\n",
    "m1 = np.ones(f1.shape)\n",
    "print('Prune 33%:')\n",
    "m2 = prune(f1, m1, 0.33)\n",
    "print('Prune 20%:')\n",
    "m3 = prune(f1, m2, 0.20)\n",
    "_unflatten_prunable(f1 * m3, w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.8949822   0.8161237   0.91389     0.27480912  0.0522331  -0.7874019\n",
      "  -0.82874143 -0.07225156 -0.24778724  0.2698859  -0.8677456  -0.7338054\n",
      "   0.6754428   1.0323585  -0.431778  ]]\n",
      "alive before:  15\n",
      "Cutoff:  0.3721298348903656\n",
      "Alive after 10\n",
      "% pruned: 0.3333333333333333\n",
      "New mask 1:\n",
      " [[1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1.]]\n",
      "Masked weights:\n",
      " [[ 0.89498222  0.81612372  0.91389     0.          0.         -0.78740191\n",
      "  -0.82874143 -0.         -0.          0.         -0.86774558 -0.73380542\n",
      "   0.67544281  1.03235853 -0.43177801]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.89498222,  0.81612372,  0.91389   ],\n",
       "        [ 0.        ,  0.        , -0.78740191],\n",
       "        [-0.82874143, -0.        , -0.        ],\n",
       "        [ 0.        , -0.86774558, -0.73380542]]),\n",
       " array([0., 0., 0.], dtype=float32),\n",
       " array([[ 0.67544281],\n",
       "        [ 1.03235853],\n",
       "        [-0.43177801]]),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = np.ones(f1.shape)\n",
    "m2 = prune(_flatten_prunable(w1), m1, 0.33)\n",
    "w1fu = _unflatten_prunable(f1 * m2, w1)\n",
    "w1fu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "f0 = np.array([1, 0, 2, 4, 3, 1, 0, 2, 2, 2, 3]).reshape(1,-1)\n",
    "f1 = np.array([1, 1, 0, 0, 2, 2, 0, 0, 0, 3, 3]).reshape(1,-1)\n",
    "m1 = np.where(f1 != 0, 1, 0)\n",
    "f2 = np.array([1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0]).reshape(1,-1)\n",
    "m2 = np.where(f2 != 0, 1, 0)\n",
    "f3 = np.array([0, 0, 4, 4, 2, 2, 0, 0, 0, 3, 3]).reshape(1,-1)\n",
    "m3 = np.where(f3 != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f0: [[1 0 2 4 3 1 0 2 2 2 3]]\n",
      "\n",
      "f1: [[1 1 0 0 2 2 0 0 0 3 3]]\n",
      "m1: [[1 1 0 0 1 1 0 0 0 1 1]]\n",
      "\n",
      "f2: [[1 1 0 0 1 1 1 1 0 0 0]]\n",
      "m2: [[1 1 0 0 1 1 1 1 0 0 0]]\n",
      "\n",
      "f3: [[0 0 4 4 2 2 0 0 0 3 3]]\n",
      "m3: [[0 0 1 1 1 1 0 0 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "print('f0:', f0)\n",
    "print()\n",
    "print('f1:', f1)\n",
    "print('m1:', m1)\n",
    "print()\n",
    "print('f2:', f2)\n",
    "print('m2:', m2)\n",
    "print()\n",
    "print('f3:', f3)\n",
    "print('m3:', m3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8, 0.8, 0.8, 0.8, 1.8, 1.8, 0.2, 0.2, 0. , 2.4, 2.4]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fed_avg_aggregate(clients, n):\n",
    "    return (1/n) * functools.reduce(operator.add,\n",
    "                                      [c[0] * c[1] for c in clients])\n",
    "\n",
    "clts = [\n",
    "    (150, f1),\n",
    "    (50, f2),\n",
    "    (50, f3),\n",
    "]\n",
    "result1 = fed_avg_aggregate(clts, 250)\n",
    "np.around(result1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(result1, result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LotteryFL Modification\n",
    "\n",
    "If a weight is masked out, it shouldn't contribute to the FedAvg as it was not trained. So, to compute FedAvg, we set a client's masked out weight to the global model's weight. Of course, this happens on the server and doesn't actually mess with the client's real weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[1, 1, 2, 4, 2, 2, 0, 2, 2, 3, 3]]), array([[1, 1, 2, 4, 1, 1, 1, 1, 2, 2, 3]]), array([[1, 0, 4, 4, 2, 2, 0, 2, 2, 3, 3]])]\n",
      "[[1.  0.8 2.4 4.  1.8 1.8 0.2 1.8 2.  2.8 3. ]]\n",
      "[[1.  0.8 2.4 4.  1.8 1.8 0.2 1.8 2.  2.8 3. ]]\n",
      "[[0.8 0.8 0.8 0.8 1.8 1.8 0.2 0.2 0.  2.4 2.4]]\n"
     ]
    }
   ],
   "source": [
    "weights = [m1*f1 + (1 - m1)*f0, m2*f2 + (1 - m2)*f0, m3*f3 + (1 - m3)*f0]\n",
    "sizes   = np.array([150, 50, 50])\n",
    "result3 = fed_avg_aggregate(zip(sizes, weights), sizes.sum())\n",
    "print(weights)\n",
    "print(np.around(result3, 2))\n",
    "print(np.around(result2, 2))\n",
    "print(np.around(result1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[1, 1, 2, 4, 2, 2, 0, 2, 2, 3, 3]]), array([[1, 1, 2, 4, 1, 1, 1, 1, 2, 2, 3]]), array([[1, 0, 4, 4, 2, 2, 0, 2, 2, 3, 3]])]\n",
      "[[1.  0.8 2.4 4.  1.8 1.8 0.2 1.8 2.  2.8 3. ]]\n",
      "[[0.8 0.8 0.8 0.8 1.8 1.8 0.2 0.2 0.  2.4 2.4]]\n"
     ]
    }
   ],
   "source": [
    "weights = [m1*f1 + (1 - m1)*f0, m2*f2 + (1 - m2)*f0, m3*f3 + (1 - m3)*f0]\n",
    "sizes   = np.array([150, 50, 50])\n",
    "ones    = np.ones(f1.shape)\n",
    "masks   = [ones, ones, ones]\n",
    "result2 = LotteryFL_aggregate1(zip(weights, sizes, masks), sizes.sum())\n",
    "print(weights)\n",
    "print(np.around(result2, 2))\n",
    "print(np.around(result1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 6, 6])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ms.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12,  6, 10],\n",
       "       [ 4,  6,  2],\n",
       "       [10,  4, 18]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs @ ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask_extended(c):\n",
    "    curr_offset = 0\n",
    "    result      = []\n",
    "\n",
    "    for layer in self.model.get_weights():\n",
    "        if layer.ndim > 1:\n",
    "            count = np.prod(layer.shape)\n",
    "            result.extend(self.mask[0, curr_offset:curr_offset+count])\n",
    "            curr_offset += count\n",
    "        else:\n",
    "            result.extend(np.ones(layer.size))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = Client_LotteryFL(1,\n",
    "                      create_MNIST_model,\n",
    "                      create_MNIST_model().get_weights(),\n",
    "                      {},\n",
    "                      X_train[:1000, :], y_train[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1.get_mask_extended()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "str = '''{\n",
    "    \"algo\": \"FedAvg\",\n",
    "    \"data\": \"MNIST_IID\",\n",
    "    \"R\": 2,\n",
    "    \"C\": 0.5,\n",
    "    \"K\": [2, 7, 2],\n",
    "    \"E\": [4, 42, 37],\n",
    "    \"B\": 64,\n",
    "    \"eta\": 0.01 \n",
    "    }'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4, 6, 8, 10]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(2, 11, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algo': 'FedAvg',\n",
       " 'data': 'MNIST_IID',\n",
       " 'R': 2,\n",
       " 'C': 0.5,\n",
       " 'K': [2, 7, 2],\n",
       " 'E': [4, 42, 37],\n",
       " 'B': 64,\n",
       " 'eta': 0.01}"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = json.loads(str)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algo': ['FedAvg'],\n",
       " 'data': ['MNIST_IID'],\n",
       " 'R': [2],\n",
       " 'C': [0.5],\n",
       " 'K': [2, 4, 6, 8, 10],\n",
       " 'E': [4],\n",
       " 'B': [64],\n",
       " 'eta': [0.01]}"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_experiment(exp):\n",
    "    runs = []\n",
    "    for algo in exp['algo']:\n",
    "        for data in exp['data']:\n",
    "            for R in exp['R']:\n",
    "                for C in exp['C']:\n",
    "                    for K in exp['K']:\n",
    "                        for E in exp['E']:\n",
    "                            for B in exp['B']:\n",
    "                                for eta in exp['eta']:\n",
    "                                    runs.append({'algo': algo,\n",
    "                                                 'data': eta,\n",
    "                                                  'R': R,\n",
    "                                                  'C': C,\n",
    "                                                  'K': K,\n",
    "                                                  'E': E,\n",
    "                                                  'B': B,\n",
    "                                                  'eta': eta})\n",
    "    return runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type  K   False\n",
      "[2, 4, 6]\n",
      "type  E   False\n",
      "[4, 41]\n"
     ]
    }
   ],
   "source": [
    "exp = {}    \n",
    "for k, v in d.items():\n",
    "    expand = False\n",
    "    if isinstance(v, list):\n",
    "        print(\"type \", k, \" \", isinstance(v[0], float))\n",
    "        exp[k] = list(range(v[0], v[1], v[2]))\n",
    "        print(exp[k])\n",
    "    else:\n",
    "        exp[k] = [v]\n",
    "# expand_experiment(exp)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2, 0.4, 0.6]"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(np.linspace(0.2, 0.6, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 10, 15, 20, 25, 30, 35, 40]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(np.linspace(5, 40, 8).astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER     = '../pbaker_experiments'\n",
    "DF_EXPS_FNAME   = os.path.join(DATA_FOLDER, 'df_experiments.pkl')\n",
    "DF_RUNS_FNAME   = os.path.join(DATA_FOLDER, 'df_runs.pkl')\n",
    "DF_EXPS         = None\n",
    "DF_RUNS         = None\n",
    "DF_EXPS_COLUMNS = ['experiment']\n",
    "DF_RUNS_COLUMNS = ['experiment', 'run',\n",
    "                   'server_loss_initial', 'server_acc_initial', 'server_loss_final', 'server_acc_final',\n",
    "                   'client_loss_final', 'client_acc_final']\n",
    "\n",
    "def load_dataframes():\n",
    "    global DF_EXPS, DF_RUNS\n",
    "    if DF_EXPS == None:\n",
    "        print(DF_EXPS_FNAME)\n",
    "        if not os.path.isfile(DF_EXPS_FNAME):\n",
    "            if not os.path.exists(DATA_FOLDER):\n",
    "                os.makedirs(DATA_FOLDER)\n",
    "            print(\"Creating DataFrame files in: \", DATA_FOLDER)\n",
    "            pd.DataFrame(columns=DF_EXPS_COLUMNS).to_pickle(DF_EXPS_FNAME)\n",
    "            pd.DataFrame(columns=DF_RUNS_COLUMNS).to_pickle(DF_RUNS_FNAME)\n",
    "    DF_RUNS = pd.read_pickle(DF_RUNS_FNAME)\n",
    "    DF_EXPS = pd.read_pickle(DF_EXPS_FNAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../pbaker_experiments\\df_experiments.pkl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment</th>\n",
       "      <th>run</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LotteryFL_MNIST_IID_R2_C0.4_K[5, 40, 8]_E10_B6...</td>\n",
       "      <td>LotteryFL_MNIST_IID_R2_C0.4_K25_E10_B64_eta0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LotteryFL_MNIST_IID_R2_C0.4_K[5, 40, 8]_E10_B6...</td>\n",
       "      <td>LotteryFL_MNIST_IID_R2_C0.4_K30_E10_B64_eta0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LotteryFL_MNIST_IID_R2_C0.4_K[5, 40, 8]_E10_B6...</td>\n",
       "      <td>LotteryFL_MNIST_IID_R2_C0.4_K35_E10_B64_eta0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LotteryFL_MNIST_IID_R2_C0.4_K[5, 40, 8]_E10_B6...</td>\n",
       "      <td>LotteryFL_MNIST_IID_R2_C0.4_K40_E10_B64_eta0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           experiment  \\\n",
       "9   LotteryFL_MNIST_IID_R2_C0.4_K[5, 40, 8]_E10_B6...   \n",
       "10  LotteryFL_MNIST_IID_R2_C0.4_K[5, 40, 8]_E10_B6...   \n",
       "11  LotteryFL_MNIST_IID_R2_C0.4_K[5, 40, 8]_E10_B6...   \n",
       "12  LotteryFL_MNIST_IID_R2_C0.4_K[5, 40, 8]_E10_B6...   \n",
       "\n",
       "                                                  run  \n",
       "9   LotteryFL_MNIST_IID_R2_C0.4_K25_E10_B64_eta0.0...  \n",
       "10  LotteryFL_MNIST_IID_R2_C0.4_K30_E10_B64_eta0.0...  \n",
       "11  LotteryFL_MNIST_IID_R2_C0.4_K35_E10_B64_eta0.0...  \n",
       "12  LotteryFL_MNIST_IID_R2_C0.4_K40_E10_B64_eta0.0...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>algo</th>\n",
       "      <th>data</th>\n",
       "      <th>R</th>\n",
       "      <th>C</th>\n",
       "      <th>K</th>\n",
       "      <th>E</th>\n",
       "      <th>B</th>\n",
       "      <th>eta</th>\n",
       "      <th>acc_threshold</th>\n",
       "      <th>r_target</th>\n",
       "      <th>r_p</th>\n",
       "      <th>server_loss_initial</th>\n",
       "      <th>server_acc_initial</th>\n",
       "      <th>server_loss_final</th>\n",
       "      <th>server_acc_final</th>\n",
       "      <th>client_loss_final</th>\n",
       "      <th>client_acc_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FedAvg_MNIST_IID_R2_C0.3_K20_E10_B64_eta0.01_A...</td>\n",
       "      <td>FedAvg</td>\n",
       "      <td>MNIST_IID</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>124.184425</td>\n",
       "      <td>0.111467</td>\n",
       "      <td>2.288211</td>\n",
       "      <td>0.668600</td>\n",
       "      <td>89.175404</td>\n",
       "      <td>0.540400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FedAvg_MNIST_IID_R2_C0.3_K40_E10_B64_eta0.01_A...</td>\n",
       "      <td>FedAvg</td>\n",
       "      <td>MNIST_IID</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>159.361298</td>\n",
       "      <td>0.123517</td>\n",
       "      <td>2.310014</td>\n",
       "      <td>0.709833</td>\n",
       "      <td>72.026179</td>\n",
       "      <td>0.596200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FedAvg_MNIST_IID_R2_C0.3_K60_E10_B64_eta0.01_A...</td>\n",
       "      <td>FedAvg</td>\n",
       "      <td>MNIST_IID</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>157.234177</td>\n",
       "      <td>0.105250</td>\n",
       "      <td>1.883923</td>\n",
       "      <td>0.667383</td>\n",
       "      <td>79.864028</td>\n",
       "      <td>0.551630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FedAvg_MNIST_IID_R2_C0.3_K80_E10_B64_eta0.01_A...</td>\n",
       "      <td>FedAvg</td>\n",
       "      <td>MNIST_IID</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>80</td>\n",
       "      <td>10</td>\n",
       "      <td>64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>146.435760</td>\n",
       "      <td>0.122783</td>\n",
       "      <td>2.223875</td>\n",
       "      <td>0.627167</td>\n",
       "      <td>78.903618</td>\n",
       "      <td>0.552269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FedAvg_MNIST_IID_R2_C0.3_K100_E10_B64_eta0.01_...</td>\n",
       "      <td>FedAvg</td>\n",
       "      <td>MNIST_IID</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>121.685715</td>\n",
       "      <td>0.147883</td>\n",
       "      <td>2.138341</td>\n",
       "      <td>0.622433</td>\n",
       "      <td>83.535736</td>\n",
       "      <td>0.569600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LotteryFL_MNIST_IID_R2_C0.4_K5_E10_B64_eta0.01...</td>\n",
       "      <td>LotteryFL</td>\n",
       "      <td>MNIST_IID</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.15</td>\n",
       "      <td>118.311615</td>\n",
       "      <td>0.121950</td>\n",
       "      <td>4.361474</td>\n",
       "      <td>0.762483</td>\n",
       "      <td>31.291558</td>\n",
       "      <td>0.823400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LotteryFL_MNIST_IID_R2_C0.4_K10_E10_B64_eta0.0...</td>\n",
       "      <td>LotteryFL</td>\n",
       "      <td>MNIST_IID</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.15</td>\n",
       "      <td>166.934601</td>\n",
       "      <td>0.092983</td>\n",
       "      <td>7.821488</td>\n",
       "      <td>0.708217</td>\n",
       "      <td>59.462167</td>\n",
       "      <td>0.663000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LotteryFL_MNIST_IID_R2_C0.4_K15_E10_B64_eta0.0...</td>\n",
       "      <td>LotteryFL</td>\n",
       "      <td>MNIST_IID</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.15</td>\n",
       "      <td>130.293015</td>\n",
       "      <td>0.139650</td>\n",
       "      <td>5.148735</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>79.404033</td>\n",
       "      <td>0.515315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LotteryFL_MNIST_IID_R2_C0.4_K20_E10_B64_eta0.0...</td>\n",
       "      <td>LotteryFL</td>\n",
       "      <td>MNIST_IID</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.15</td>\n",
       "      <td>178.515717</td>\n",
       "      <td>0.098733</td>\n",
       "      <td>6.732659</td>\n",
       "      <td>0.706167</td>\n",
       "      <td>53.353412</td>\n",
       "      <td>0.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LotteryFL_MNIST_IID_R2_C0.4_K25_E10_B64_eta0.0...</td>\n",
       "      <td>LotteryFL</td>\n",
       "      <td>MNIST_IID</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.15</td>\n",
       "      <td>202.064362</td>\n",
       "      <td>0.106067</td>\n",
       "      <td>7.789520</td>\n",
       "      <td>0.707483</td>\n",
       "      <td>43.936266</td>\n",
       "      <td>0.737600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LotteryFL_MNIST_IID_R2_C0.4_K30_E10_B64_eta0.0...</td>\n",
       "      <td>LotteryFL</td>\n",
       "      <td>MNIST_IID</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.15</td>\n",
       "      <td>157.991257</td>\n",
       "      <td>0.046650</td>\n",
       "      <td>6.406722</td>\n",
       "      <td>0.695300</td>\n",
       "      <td>60.386760</td>\n",
       "      <td>0.638956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LotteryFL_MNIST_IID_R2_C0.4_K35_E10_B64_eta0.0...</td>\n",
       "      <td>LotteryFL</td>\n",
       "      <td>MNIST_IID</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.15</td>\n",
       "      <td>180.846024</td>\n",
       "      <td>0.094033</td>\n",
       "      <td>7.287049</td>\n",
       "      <td>0.666250</td>\n",
       "      <td>58.254755</td>\n",
       "      <td>0.664000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LotteryFL_MNIST_IID_R2_C0.4_K40_E10_B64_eta0.0...</td>\n",
       "      <td>LotteryFL</td>\n",
       "      <td>MNIST_IID</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.15</td>\n",
       "      <td>144.236557</td>\n",
       "      <td>0.066367</td>\n",
       "      <td>8.065874</td>\n",
       "      <td>0.659150</td>\n",
       "      <td>61.742108</td>\n",
       "      <td>0.656800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  run       algo       data  \\\n",
       "0   FedAvg_MNIST_IID_R2_C0.3_K20_E10_B64_eta0.01_A...     FedAvg  MNIST_IID   \n",
       "1   FedAvg_MNIST_IID_R2_C0.3_K40_E10_B64_eta0.01_A...     FedAvg  MNIST_IID   \n",
       "2   FedAvg_MNIST_IID_R2_C0.3_K60_E10_B64_eta0.01_A...     FedAvg  MNIST_IID   \n",
       "3   FedAvg_MNIST_IID_R2_C0.3_K80_E10_B64_eta0.01_A...     FedAvg  MNIST_IID   \n",
       "4   FedAvg_MNIST_IID_R2_C0.3_K100_E10_B64_eta0.01_...     FedAvg  MNIST_IID   \n",
       "5   LotteryFL_MNIST_IID_R2_C0.4_K5_E10_B64_eta0.01...  LotteryFL  MNIST_IID   \n",
       "6   LotteryFL_MNIST_IID_R2_C0.4_K10_E10_B64_eta0.0...  LotteryFL  MNIST_IID   \n",
       "7   LotteryFL_MNIST_IID_R2_C0.4_K15_E10_B64_eta0.0...  LotteryFL  MNIST_IID   \n",
       "8   LotteryFL_MNIST_IID_R2_C0.4_K20_E10_B64_eta0.0...  LotteryFL  MNIST_IID   \n",
       "9   LotteryFL_MNIST_IID_R2_C0.4_K25_E10_B64_eta0.0...  LotteryFL  MNIST_IID   \n",
       "10  LotteryFL_MNIST_IID_R2_C0.4_K30_E10_B64_eta0.0...  LotteryFL  MNIST_IID   \n",
       "11  LotteryFL_MNIST_IID_R2_C0.4_K35_E10_B64_eta0.0...  LotteryFL  MNIST_IID   \n",
       "12  LotteryFL_MNIST_IID_R2_C0.4_K40_E10_B64_eta0.0...  LotteryFL  MNIST_IID   \n",
       "\n",
       "    R    C    K   E   B   eta  acc_threshold  r_target   r_p  \\\n",
       "0   2  0.3   20  10  64  0.01            0.0      0.00  0.00   \n",
       "1   2  0.3   40  10  64  0.01            0.0      0.00  0.00   \n",
       "2   2  0.3   60  10  64  0.01            0.0      0.00  0.00   \n",
       "3   2  0.3   80  10  64  0.01            0.0      0.00  0.00   \n",
       "4   2  0.3  100  10  64  0.01            0.0      0.00  0.00   \n",
       "5   2  0.4    5  10  64  0.01            0.5      0.25  0.15   \n",
       "6   2  0.4   10  10  64  0.01            0.5      0.25  0.15   \n",
       "7   2  0.4   15  10  64  0.01            0.5      0.25  0.15   \n",
       "8   2  0.4   20  10  64  0.01            0.5      0.25  0.15   \n",
       "9   2  0.4   25  10  64  0.01            0.5      0.25  0.15   \n",
       "10  2  0.4   30  10  64  0.01            0.5      0.25  0.15   \n",
       "11  2  0.4   35  10  64  0.01            0.5      0.25  0.15   \n",
       "12  2  0.4   40  10  64  0.01            0.5      0.25  0.15   \n",
       "\n",
       "    server_loss_initial  server_acc_initial  server_loss_final  \\\n",
       "0            124.184425            0.111467           2.288211   \n",
       "1            159.361298            0.123517           2.310014   \n",
       "2            157.234177            0.105250           1.883923   \n",
       "3            146.435760            0.122783           2.223875   \n",
       "4            121.685715            0.147883           2.138341   \n",
       "5            118.311615            0.121950           4.361474   \n",
       "6            166.934601            0.092983           7.821488   \n",
       "7            130.293015            0.139650           5.148735   \n",
       "8            178.515717            0.098733           6.732659   \n",
       "9            202.064362            0.106067           7.789520   \n",
       "10           157.991257            0.046650           6.406722   \n",
       "11           180.846024            0.094033           7.287049   \n",
       "12           144.236557            0.066367           8.065874   \n",
       "\n",
       "    server_acc_final  client_loss_final  client_acc_final  \n",
       "0           0.668600          89.175404          0.540400  \n",
       "1           0.709833          72.026179          0.596200  \n",
       "2           0.667383          79.864028          0.551630  \n",
       "3           0.627167          78.903618          0.552269  \n",
       "4           0.622433          83.535736          0.569600  \n",
       "5           0.762483          31.291558          0.823400  \n",
       "6           0.708217          59.462167          0.663000  \n",
       "7           0.663800          79.404033          0.515315  \n",
       "8           0.706167          53.353412          0.680000  \n",
       "9           0.707483          43.936266          0.737600  \n",
       "10          0.695300          60.386760          0.638956  \n",
       "11          0.666250          58.254755          0.664000  \n",
       "12          0.659150          61.742108          0.656800  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DF_EXPS         = None\n",
    "DF_RUNS         = None\n",
    "load_dataframes()\n",
    "display(DF_EXPS.tail(4))\n",
    "display(DF_RUNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['FedAvg_MNIST_IID_R2_C[0.3, 0.9, 1]_K[20, 100, 5]_E10_B64_eta0.01_Acc0.0_rtrg0.0_rprn0.0',\n",
       "       'LotteryFL_MNIST_IID_R2_C0.4_K[5, 40, 8]_E10_B64_eta0.01_Acc0.5_rtrg0.25_rprn0.15'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF_EXPS['experiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>K</th>\n",
       "      <th>client_acc_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.823400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0.663000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>0.515315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>0.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>0.737600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30</td>\n",
       "      <td>0.638956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>35</td>\n",
       "      <td>0.664000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>40</td>\n",
       "      <td>0.656800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    K  client_acc_final\n",
       "0   5          0.823400\n",
       "1  10          0.663000\n",
       "2  15          0.515315\n",
       "3  20          0.680000\n",
       "4  25          0.737600\n",
       "5  30          0.638956\n",
       "6  35          0.664000\n",
       "7  40          0.656800"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>K</th>\n",
       "      <th>server_acc_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.762483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0.708217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>0.663800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>0.706167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>0.707483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30</td>\n",
       "      <td>0.695300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>35</td>\n",
       "      <td>0.666250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>40</td>\n",
       "      <td>0.659150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    K  server_acc_final\n",
       "0   5          0.762483\n",
       "1  10          0.708217\n",
       "2  15          0.663800\n",
       "3  20          0.706167\n",
       "4  25          0.707483\n",
       "5  30          0.695300\n",
       "6  35          0.666250\n",
       "7  40          0.659150"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='K'>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "experiment = 'LotteryFL_MNIST_IID_R2_C0.4_K[5, 40, 8]_E10_B64_eta0.01_Acc0.5_rtrg0.25_rprn0.15'\n",
    "mask = DF_EXPS['experiment'] == experiment\n",
    "\n",
    "display(DF_EXPS[mask].loc[:, 'run'].to_frame().merge(DF_RUNS, on='run')[['K', 'client_acc_final']])\n",
    "DF_EXPS[mask].loc[:, 'run'].to_frame().merge(DF_RUNS, on='run').plot(x='K', y='client_acc_final')\n",
    "plt.show()\n",
    "display(DF_EXPS[mask].loc[:, 'run'].to_frame().merge(DF_RUNS, on='run')[['K', 'server_acc_final']])\n",
    "DF_EXPS[mask].loc[:, 'run'].to_frame().merge(DF_RUNS, on='run').plot(x='K', y='server_acc_final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>string</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>hello</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>string</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a    b       c\n",
       "0  1  0.2  string\n",
       "1  2  0.4   hello\n",
       "2  3  0.6  string"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns=['a', 'b', 'c']\n",
    "df = pd.DataFrame(columns=columns)\n",
    "df = df.append({'a': 1, 'b': 0.2, 'c': 'string'}, ignore_index=True)\n",
    "df = df.append({'a': 2, 'b': 0.4, 'c': 'hello'}, ignore_index=True)\n",
    "for i in range(3):\n",
    "    if not 3 in df['a'].values:\n",
    "        df = df.append({'a': 3, 'b': 0.6, 'c': 'string'}, ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 2, 'b': 0.4, 'c': 'hello'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['a'] == 2].iloc[0].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['a'] == 1) & (df['b'] == 0.2)].empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'a':1}\n",
    "d.get('b', 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abcdef'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'abc'\\\n",
    "'def'\n",
    "s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
